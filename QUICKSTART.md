# ğŸš€ Multilingual Hinglish NLP v2.0 - Quick Start

## What's New in v2.0?

**Massive Accuracy Improvements:**
- âœ… **Hinglish accuracy:** 55% â†’ **92%** (+37% improvement!)
- âœ… **English accuracy:** 93% â†’ **94%**
- âœ… **176 languages supported** (previously only 2)
- âœ… **Token-level language detection** with HingBERT (96% accuracy)
- âœ… **Smart routing:** Automatically uses best model for each language

**New Models:**
- ğŸ¤– **HingBERT** - Token-level Hinglish detection (state-of-the-art)
- ğŸ¤– **CM-BERT** - Hinglish/English sentiment (92-94% accuracy)
- ğŸ¤– **XLM-RoBERTa** - Multilingual sentiment (87% accuracy, 100+ languages)
- ğŸŒ **FastText** - Quick language detection (176 languages)

---

## âš¡ Quick Setup (5 minutes)

### Prerequisites
- Python 3.10+ (3.12.6 recommended)
- 5 GB free disk space
- 4 GB RAM minimum

### Installation

```powershell
# Clone repository
git clone https://github.com/YadneshTeli/Code-mixed-NLP.git
cd Code-mixed-NLP

# Run automated setup
python setup.py
```

The setup script will:
1. Install all dependencies (~2.1 GB models)
2. Download spaCy model
3. Download NLTK data
4. Verify installation
5. Run quick tests

**Or manual installation:**
```powershell
pip install -r requirements.txt
python -m spacy download en_core_web_sm
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

---

## ğŸ¯ Quick Test

Start the API:
```powershell
python app/main.py
```

Visit: **http://localhost:8000/docs**

Test the new V2 endpoint:
```powershell
curl -X POST "http://localhost:8000/api/v2/analyze" `
     -H "Content-Type: application/json" `
     -d '{"text": "Yaar this movie is too good! Bahut maza aaya ğŸ¬"}'
```

Expected response:
```json
{
  "sentiment": "positive",
  "confidence": 0.94,
  "route": "hinglish",
  "model_used": "CM-BERT",
  "language_detection": {
    "detected_language": "hi",
    "is_hinglish": true,
    "token_level_detection": {
      "hindi_percentage": 45.0,
      "english_percentage": 50.0,
      "is_code_mixed": true
    }
  },
  "processing_time_ms": 285.42
}
```

---

## ğŸ“š API Endpoints

### V2 Endpoints (Multilingual - Recommended)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v2/analyze` | POST | Multilingual sentiment analysis with smart routing |
| `/api/v2/analyze/batch` | POST | Batch analysis for multiple texts |
| `/api/v2/languages` | GET | Get supported languages (176 total) |
| `/api/v2/health` | GET | Health check for all models |

### V1 Endpoints (Legacy - Still Supported)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/analyze` | POST | Full analysis (original pipeline) |
| `/api/v1/analyze-sentiment` | POST | Sentiment only |
| `/api/v1/detect-language` | POST | Language detection |
| `/api/v1/preprocess` | POST | Text preprocessing |

---

## ğŸŒ Supported Languages

**Hinglish-Optimized (92-96% accuracy):**
- Hindi (à¤¹à¤¿à¤‚à¤¦à¥€)
- English
- Code-mixed Hinglish

**Multilingual Support (87% accuracy):**
- **8 direct support:** Arabic, English, French, German, Hindi, Italian, Portuguese, Spanish
- **100+ via transfer learning:** All major world languages
- **176 total detection:** FastText can identify 176 languages

---

## ğŸ§ª Running Tests

```powershell
# Run all tests (46 tests - 100% passing)
pytest app/tests/ -v

# Run specific test file
pytest app/tests/test_api.py -v
pytest app/tests/test_hybrid_pipeline.py -v

# Quick test summary
pytest app/tests/ -q

# With coverage
pytest app/tests/ --cov=app --cov-report=html
```

**Test Results:**
- âœ… 46 tests passing (100%)
- âœ… 0 warnings
- âœ… All FastText, HingBERT, and pipeline tests passing

---

## ğŸ“Š Performance Comparison

| Metric | v1.0 | v2.0 | Change |
|--------|------|------|--------|
| **Hinglish Accuracy** | 55% | 92% | **+37%** ğŸ¯ |
| **English Accuracy** | 93% | 94% | +1% |
| **Languages** | 2 | 176 | **+174** ğŸŒ |
| **Model Size** | 268 MB | 2.1 GB | +1.8 GB |
| **Response Time** | 100-200ms | 200-350ms | +150ms |
| **Token Detection** | âŒ | âœ… | **NEW** |

---

## ğŸš€ Deployment

Deploy to Railway in 3 steps:

```powershell
# 1. Install Railway CLI
npm install -g @railway/cli

# 2. Login and initialize
railway login
railway init

# 3. Deploy
railway up
```

Your API will be live at: `https://your-app.railway.app`

**Railway FREE tier compatible:**
- Image: 2.3 GB (limit: 4 GB) âœ…
- RAM: 3-4 GB (limit: 8 GB) âœ…

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

---

## ğŸ“– Documentation

**Main Documentation (11 essential files):**
- **[docs/INDEX.md](docs/INDEX.md)** - Documentation index
- **[docs/MULTILINGUAL_API_v2.md](docs/MULTILINGUAL_API_v2.md)** - Complete API reference
- **[docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)** - Deployment guide
- **[docs/API_TEST_SAMPLES.md](docs/API_TEST_SAMPLES.md)** - Test examples
- **[docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md)** - Project structure

**Technical & Training:**
- **[docs/technical/](docs/technical/)** - Detector status, NumPy compatibility, migration guide
- **[docs/training/](docs/training/)** - Training quickstart and alternatives

**Interactive API Docs:**
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

---

## ğŸ¯ Use Cases

### Best for Hinglish (Route: hinglish)
```python
texts = [
    "Yaar this movie is too good! ğŸ¬",
    "Bahut boring tha yaar",
    "Kya amazing performance! ğŸ‰"
]
```

### Best for Multilingual (Route: multilingual)
```python
texts = [
    "C'est magnifique!",  # French
    "Â¡IncreÃ­ble pelÃ­cula!",  # Spanish
    "Ù‡Ø°Ø§ Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ø§!",  # Arabic
    "Questo Ã¨ fantastico!"  # Italian
]
```

---

## ğŸ”§ Model Architecture

```
Input Text
    â†“
HybridPreprocessor (NLTK + spaCy)
    â†“
FastTextDetector (10-20ms, 176 languages)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Is Hinglish/Hindi/English?          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ YES â†’ HingBERT (96% token detection)â”‚
â”‚       â†“                              â”‚
â”‚       CM-BERT (92-94% sentiment)    â”‚
â”‚                                      â”‚
â”‚ NO â†’ XLM-RoBERTa (87% multilingual) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Tips

1. **Use V2 for new projects** - Better accuracy and multilingual support
2. **First request is slower** - Models lazy-load on first use (~10-15 seconds)
3. **Batch for efficiency** - Use `/api/v2/analyze/batch` for multiple texts
4. **Check language support** - Visit `/api/v2/languages`
5. **Monitor route** - Response shows which model was used

---

## ğŸ› Troubleshooting

**Models not loading?**
```powershell
# Re-download spaCy model
python -m spacy download en_core_web_sm

# Re-download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

**Import errors?**
```powershell
# Reinstall requirements
pip install -r requirements.txt --force-reinstall
```

**Out of memory?**
- Models need 3-4 GB RAM
- Close other applications
- Use batch processing for multiple texts

---

## ğŸ“ Migration from v1.0

**API Changes:**
- Response field: `label` â†’ `sentiment`
- New fields: `route`, `model_used`, `language_detection`
- V1 endpoints still work (backward compatible)

**Example Migration:**
```python
# OLD (v1.0)
response = requests.post("/api/v1/analyze-sentiment", json={"text": "..."})
sentiment = response.json()["label"]

# NEW (v2.0)
response = requests.post("/api/v2/analyze", json={"text": "..."})
sentiment = response.json()["sentiment"]
route = response.json()["route"]  # NEW: See which model was used
```

---

## ğŸ¤ Contributing

Contributions welcome! See open issues or create a new one.

---

## ğŸ“„ License

MIT License - See LICENSE file

---

## ğŸ™ Credits

**Models:**
- [HingBERT](https://huggingface.co/l3cube-pune/hing-roberta) - L3Cube Pune
- [CM-BERT](https://huggingface.co/l3cube-pune/hing-sentiment-roberta) - L3Cube Pune
- [XLM-RoBERTa](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment) - Cardiff NLP

**Frameworks:**
- FastAPI, PyTorch, Transformers, spaCy, NLTK

---

**Version:** 2.0.0  
**Author:** Yadnesh Teli  
**Last Updated:** January 2025  
**Status:** âœ… Production Ready

---

ğŸ‰ **Start building multilingual NLP applications today!**
